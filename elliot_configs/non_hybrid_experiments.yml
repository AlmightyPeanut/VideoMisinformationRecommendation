experiment:
  dataset: yaudit_non_hybrid
  data_config:
    strategy: hierarchy
    root_folder: data/splitting/non_hybrid
#    strategy: dataset
#    dataset_path: ../data/base_data/base_data_0_norec_0_rec_1_watched.tsv
#  splitting:
#    save_on_disk: True
#    save_folder: ../data/splitting/non_hybrid
#    test_splitting:
#        strategy: random_subsampling
#        test_ratio: 0.1
  top_k: 10
  evaluation:
    simple_metrics: [ nDCG,Precision,Recall,MRR,NS,SERP-MS ]
    relevance_threshold: 1
    paired_ttest: True
    wilcoxon_test: True
  models:
#    MostPop:
#      meta:
#        save_recs: True
#    Random:
#      meta:
#        save_recs: True
#      random_seed: 42
#    ItemKNN:
#      meta:
#        save_recs: True
#      neighbors: 100
#      similarity: cosine
#      implementation: aiolli
#    UserKNN:
#      meta:
#        save_recs: True
#      neighbors: 500
#      similarity: cosine
#      implementation: aiolli
#    MF:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 256
#      factors: 5
#      lr: 0.001
#      reg: 0.1
#    NeuMF:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 128
#      mf_factors: 50
#      mlp_factors: 500
#      mlp_hidden_size: (64,64,64,64,64,32)
#      lr: 0.001
#      dropout: .1
#      is_mf_train: True
#      is_mlp_train: True
#    DMF:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 128
#      lr: 0.0001
#      reg: 0.001
#      user_mlp: (64,32)
#      item_mlp: (64,64,64,32)
#      similarity: cosine
#    BPRMF:
#      meta:
#        save_recs: True
#      epochs: 10
#      factors: 25
#      lr: 0.001
#      bias_regularization: .01
#      user_regularization: .1
#      positive_item_regularization: .0025
#      negative_item_regularization: .0025
#      update_negative_item_factors: True
#      update_users: True
#      update_items: True
#      update_bias: True
#    CML:
#      meta:
#        save_recs: True
#      epochs: 40
#      batch_size: 32
#      factors: 10
#      lr: 0.001
#      l_w: .001
#      l_b: .001
#      margin: .5
    NonNegMF:
      meta:
        save_recs: True
      epochs: 1
      batch_size: 128
      factors: 250
      lr: 0.000001
      reg: 0.1
#    PMF:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 128
#      factors: 10
#      lr: 0.001
#      reg: 0.0025
#      gaussian_variance: 0.1
#    GMF:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 512
#      mf_factors: 10
#      lr: 0.001
#      is_edge_weight_train: True
#    LogisticMatrixFactorization:
#      meta:
#        save_recs: True
#      epochs: 40
#      batch_size: 512
#      factors: 500
#      lr: .9
#      reg: 0.1
#      alpha: 0.5
#    FFM:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 512
#      factors: 100
#      lr: 0.001
#      reg: .1
#    FunkSVD:
#      meta:
#        save_recs: True
#      epochs: 10
#      batch_size: 32
#      factors: 1000
#      lr: 0.001
#      reg_w: .1
#      reg_b: .001
#    SVDpp:
#      meta:
#        save_recs: True
#      epochs: 5
#      batch_size: 128
#      factors: 500
#      lr: 0.001
#      reg_w: .3
#      reg_b: .1
#    TODO: Convergence warning Slim:
#      meta:
#        save_recs: True
#      l1_ratio: 0.001
#      alpha: [0.001, .1, .25, .5]
#      neighborhood: [10, 50, 100, 250, 500]
  print_results_as_triplets: True
